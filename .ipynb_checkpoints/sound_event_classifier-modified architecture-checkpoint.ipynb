{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8bMse_qgCnUQ",
    "outputId": "171fa933-d034-4fba-bb2a-fd5790e1efa7"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,LSTM,TimeDistributed, SimpleRNN\n",
    "from keras.layers import Convolution2D, MaxPooling2D,MaxPooling1D,Conv1D\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "import datetime\n",
    "\n",
    "\n",
    "def reSample(data, samples):\n",
    "    r = len(data)/samples #re-sampling ratio\n",
    "    newdata = []\n",
    "    for i in range(0,samples):\n",
    "        newdata.append(data[int(i*r)])\n",
    "    return np.array(newdata)\n",
    "  \n",
    "  \n",
    "train_subjects = ['s07', 's16', 's09', 's13', 's04', 's11', 's15', 's01', 's12', 's10', 's06', 's08']\n",
    "validation_subjects = ['s02', 's03']\n",
    "test_subjects = ['s05', 's17']\n",
    "\n",
    "def get_data(path,sampleSize):\n",
    "    \n",
    "    mergedActivities = ['Drinking', 'Eating', 'LyingDown', 'OpeningPillContainer', \n",
    "                          'PickingObject', 'Reading', 'SitStill', 'Sitting', 'Sleeping', \n",
    "                          'StandUp', 'UseLaptop', 'UsingPhone', 'WakeUp', 'Walking', \n",
    "                          'WaterPouring', 'Writing']\n",
    "    \n",
    "    specificActivities = ['Calling', 'Clapping', 'Falling', 'Sweeping', 'WashingHand', 'WatchingTV']\n",
    "    \n",
    "    enteringExiting = ['Entering', 'Exiting']\n",
    "    \n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    X_validation = []\n",
    "    Y_validation = []\n",
    "    \n",
    "    ## Note that 'stft_257_1' contains the STFT features with specification specified in the medium article; \n",
    "    ## https://medium.com/@chathuranga.15/sound-event-classification-using-machine-learning-8768092beafc\n",
    "    \n",
    "    for file in os.listdir(path + 'stft_257_1/'):\n",
    "        if int(file.split(\"__\")[1].split(\"_\")[0])!=1:\n",
    "          a = (np.load(path + \"stft_257_1/\" + file)).T\n",
    "          label = file.split('_')[-1].split(\".\")[0]\n",
    "          if(label in specificActivities):\n",
    "              #if(a.shape[0]>100 and a.shape[0]<500):\n",
    "                if file.split(\"_\")[0] in train_subjects:\n",
    "#                   X_train.append(reSample(a,sampleSize))\n",
    "                  X_train.append(np.mean(a,axis=1))\n",
    "#                   X_train.append(a)\n",
    "                  Y_train.append(label)\n",
    "                elif file.split(\"_\")[0] in validation_subjects:\n",
    "                  X_validation.append(np.mean(a,axis=1))\n",
    "#                   X_validation.append(a)\n",
    "                  Y_validation.append(label)\n",
    "                else:\n",
    "                  X_test.append(np.mean(a,axis=1))\n",
    "#                   X_test.append(a)\n",
    "                  Y_test.append(label)\n",
    "                  #samples[label].append(reSample(a,sampleSize))\n",
    "          elif(label in enteringExiting):\n",
    "                label = \"enteringExiting\"\n",
    "              #if(a.shape[0]>100 and a.shape[0]<500):\n",
    "                if file.split(\"_\")[0] in train_subjects:\n",
    "                  X_train.append(np.mean(a,axis=1))\n",
    "#                   X_train.append(a)\n",
    "                  Y_train.append(label)\n",
    "                elif file.split(\"_\")[0] in validation_subjects:\n",
    "                  X_validation.append(np.mean(a,axis=1))\n",
    "#                   X_validation.append(a)\n",
    "                  Y_validation.append(label)\n",
    "                else:\n",
    "                  X_test.append(np.mean(a,axis=1))\n",
    "#                   X_test.append(a)\n",
    "                  Y_test.append(label)\n",
    "                  #samples[label].append(reSample(a,sampleSize))\n",
    "          else:\n",
    "                label = \"other\"\n",
    "              #if(a.shape[0]>100 and a.shape[0]<500):\n",
    "                if file.split(\"_\")[0] in train_subjects:\n",
    "                  X_train.append(np.mean(a,axis=1))\n",
    "#                   X_train.append(a)\n",
    "                  Y_train.append(label)\n",
    "                elif file.split(\"_\")[0] in validation_subjects:\n",
    "                  X_validation.append(np.mean(a,axis=1))\n",
    "#                   X_validation.append(a)\n",
    "                  Y_validation.append(label)\n",
    "                else:\n",
    "                  X_test.append(np.mean(a,axis=1))\n",
    "#                   X_test.append(a)\n",
    "                  Y_test.append(label)\n",
    "                  \n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(Y_test)\n",
    "    X_validation = np.array(X_validation)\n",
    "    Y_validation = np.array(Y_validation)\n",
    "    \n",
    "    return X_train,Y_train,X_validation,Y_validation,X_test,Y_test\n",
    "  \n",
    "def print_M(conf_M):\n",
    "        s = \"activity,\"\n",
    "        for i in range(len(conf_M)):\n",
    "            s += lb.inverse_transform([i])[0] + \",\"\n",
    "        print(s[:-1])\n",
    "        for i in range(len(conf_M)):\n",
    "            s = \"\"\n",
    "            for j in range(len(conf_M)):\n",
    "                s += str(conf_M[i][j])\n",
    "                s += \",\"\n",
    "            print(lb.inverse_transform([i])[0],\",\", s[:-1])\n",
    "        print()\n",
    "        \n",
    "def print_M_P(conf_M):\n",
    "        s = \"activity,\"\n",
    "        for i in range(len(conf_M)):\n",
    "            s += lb.inverse_transform([i])[0] + \",\"\n",
    "        print(s[:-1])\n",
    "        for i in range(len(conf_M)):\n",
    "            s = \"\"\n",
    "            for j in range(len(conf_M)):\n",
    "                val = conf_M[i][j]/float(sum(conf_M[i]))\n",
    "                s += str(round(val,2))\n",
    "                s += \",\"\n",
    "            print(lb.inverse_transform([i])[0],\",\", s[:-1])\n",
    "        print()        \n",
    "        \n",
    "def showResult():\n",
    "  predictions = [np.argmax(y) for y in result]\n",
    "  expected = [np.argmax(y) for y in y_test]\n",
    "\n",
    "  conf_M = []\n",
    "  num_labels=y_test[0].shape[0]\n",
    "  for i in range(num_labels):\n",
    "      r = []\n",
    "      for j in range(num_labels):\n",
    "          r.append(0)\n",
    "      conf_M.append(r)\n",
    "\n",
    "  \n",
    "\n",
    "  n_tests = len(predictions)\n",
    "  for i in range(n_tests):        \n",
    "      conf_M[expected[i]][predictions[i]] += 1\n",
    "\n",
    "  print_M(conf_M)\n",
    "  print_M_P(conf_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJXscHVhEBYC"
   },
   "outputs": [],
   "source": [
    "featuresPath = \"Audio_classification/STFT_features/\"\n",
    "\n",
    "a,b,c,d,e,f = get_data(featuresPath,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-wO90syxC5d8",
    "outputId": "4128b9f5-5f37-4226-8334-4505efafb8a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training samples: 880\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_validation,Y_validation,X_test,Y_test = a,b,c,d,e,f\n",
    "\n",
    "n_samples = len(Y_train)\n",
    "print(\"No of training samples: \" + str(n_samples))\n",
    "order = np.array(range(n_samples))\n",
    "np.random.shuffle(order)\n",
    "X_train = X_train[order]\n",
    "Y_train = Y_train[order]\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(Y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(Y_test))\n",
    "y_validation = np_utils.to_categorical(lb.fit_transform(Y_validation))\n",
    "num_labels = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "e7JS59xYDB06",
    "outputId": "5b249629-b357-4bb7-a463-cc37c7e78e83",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected simple_rnn_4_input to have 3 dimensions, but got array with shape (880, 257)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-c0669168d4ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# model.summary()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\dcase2019\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dcase2019\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dcase2019\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected simple_rnn_4_input to have 3 dimensions, but got array with shape (880, 257)"
     ]
    }
   ],
   "source": [
    "num_labels = y_train.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# build model\n",
    "model = Sequential()\n",
    "\n",
    "# model.add(Dense(256, input_shape=(257,)))\n",
    "# model.add(Activation('relu'))\n",
    "# # model.add(Dropout(0.5))\n",
    "\n",
    "model.add(SimpleRNN(256, input_shape=(257, 1), activation='relu', return_sequences=True))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(SimpleRNN(256, input_shape=(257, 1), activation='relu', return_sequences=True))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "# model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=10, epochs=60,validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "eCEiuWjBDFTz",
    "outputId": "6ffca04d-d9e6-459b-dedb-8b12049ccbe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.99%\n",
      "activity,Calling,Clapping,Falling,Sweeping,WashingHand,WatchingTV,enteringExiting,other\n",
      "Calling , 7,0,2,0,0,0,0,3\n",
      "Clapping , 0,12,0,0,0,0,0,0\n",
      "Falling , 0,1,8,0,0,0,1,2\n",
      "Sweeping , 0,0,0,6,0,0,0,0\n",
      "WashingHand , 0,0,0,0,4,0,0,2\n",
      "WatchingTV , 0,0,0,0,0,3,0,3\n",
      "enteringExiting , 0,0,0,0,0,0,14,0\n",
      "other , 0,3,4,1,0,2,0,140\n",
      "\n",
      "activity,Calling,Clapping,Falling,Sweeping,WashingHand,WatchingTV,enteringExiting,other\n",
      "Calling , 0.58,0.0,0.17,0.0,0.0,0.0,0.0,0.25\n",
      "Clapping , 0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "Falling , 0.0,0.08,0.67,0.0,0.0,0.0,0.08,0.17\n",
      "Sweeping , 0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "WashingHand , 0.0,0.0,0.0,0.0,0.67,0.0,0.0,0.33\n",
      "WatchingTV , 0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.5\n",
      "enteringExiting , 0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0\n",
      "other , 0.0,0.02,0.03,0.01,0.0,0.01,0.0,0.93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_test)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(Y_test)):\n",
    "    if(np.amax(result[i])<0.5):\n",
    "#       pred = 11\n",
    "      pred = np.argmax(result[i])\n",
    "    else:\n",
    "      pred = np.argmax(result[i])\n",
    "    if np.argmax(y_test[i])==pred:\n",
    "        cnt+=1\n",
    "\n",
    "acc = str(round(cnt*100/float(len(Y_test)),2))\n",
    "print(\"Accuracy: \" + acc + \"%\")\n",
    "\n",
    "showResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfVN64yTDIhq"
   },
   "outputs": [],
   "source": [
    "## save model (optional)\n",
    "path = \"Audio_classification/Models/Modified/audio_NN_New\"+datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "model_json = model.to_json()\n",
    "with open(path+\"_acc_\"+acc+\".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(path+\"_acc_\"+acc+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qft5RNixHVHc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "activityReduced_NN_STFT_mean.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
