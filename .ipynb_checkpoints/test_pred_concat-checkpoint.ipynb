{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import noisereduce as nr\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import IPython\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Utils\n",
    "\n",
    "# Plot audio with zoomed in y axis\n",
    "def plotAudio(output):\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(20,10))\n",
    "    plt.plot(output, color='blue')\n",
    "    ax.set_xlim((0, len(output)))\n",
    "    ax.margins(2, -0.1)\n",
    "    plt.show()\n",
    "\n",
    "# Plot audio\n",
    "def plotAudio2(output):\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(20,4))\n",
    "    plt.plot(output, color='blue')\n",
    "    ax.set_xlim((0, len(output)))\n",
    "    plt.show()\n",
    "\n",
    "# Split a given long audio file on silent parts.\n",
    "# Accepts audio numpy array audio_data, window length w and hop length h, threshold_level, tolerence\n",
    "# threshold_level: Silence threshold\n",
    "# Higher tolence to prevent small silence parts from splitting the audio.\n",
    "# Returns array containing arrays of [start, end] points of resulting audio clips\n",
    "def split_audio(audio_data, w, h, threshold_level, tolerence=10):\n",
    "    split_map = []\n",
    "    start = 0\n",
    "    data = np.abs(audio_data)\n",
    "    threshold = threshold_level*np.mean(data[:20000])\n",
    "    inside_sound = False\n",
    "    near = 0\n",
    "    for i in range(0,len(data)-w, h):\n",
    "        win_mean = np.mean(data[i:i+w])\n",
    "        if(win_mean>threshold and not(inside_sound)):\n",
    "#             print(i, 'inside sound')\n",
    "            inside_sound = True\n",
    "            start = i\n",
    "        if(win_mean<=threshold and inside_sound and near>tolerence):\n",
    "#             print(i, 'outside sound')\n",
    "            inside_sound = False\n",
    "            near = 0\n",
    "            split_map.append([start, i])\n",
    "        if(inside_sound and win_mean<=threshold):\n",
    "            near += 1\n",
    "    return split_map\n",
    "\n",
    "def minMaxNormalize(arr):\n",
    "    mn = np.min(arr)\n",
    "    mx = np.max(arr)\n",
    "    return (arr-mn)/(mx-mn)\n",
    "\n",
    "def predictSound(X):\n",
    "    stfts = np.abs(librosa.stft(X, n_fft=512, hop_length=256, win_length=512))\n",
    "    stfts = np.mean(stfts,axis=1)\n",
    "#     stfts = minMaxNormalize(stfts)\n",
    "    result = model.predict(np.array([stfts]))\n",
    "    predictions = [np.argmax(y) for y in result]\n",
    "    return lb.inverse_transform([predictions[0]])[0]\n",
    "\n",
    "def get_win_mean(audio_data, w, h, threshold_level):\n",
    "    data = np.abs(audio_data)\n",
    "    win_mean = np.zeros(shape = raw_audio.shape, dtype = raw_audio.dtype)\n",
    "    threshold = threshold_level*np.mean(data[:20000])\n",
    "    print('np.mean(data[:20000]) = ', np.mean(data[:20000]))\n",
    "    print('threshold = ', threshold)\n",
    "    for i in range(0,len(data)-w, h):\n",
    "        win_mean[i] = np.mean(data[i:i+w])\n",
    "    return win_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testing data\n",
    "\n",
    "activities = ['Calling', 'Clapping', 'Drinking', 'Eating', 'Entering',\n",
    "              'Exiting', 'Falling', 'LyingDown', 'OpeningPillContainer',\n",
    "              'PickingObject', 'Reading', 'SitStill', 'Sitting', 'Sleeping',\n",
    "              'StandUp', 'Sweeping', 'UseLaptop', 'UsingPhone', 'WakeUp', 'Walking',\n",
    "              'WashingHand', 'WatchingTV', 'WaterPouring', 'Writing']\n",
    "    \n",
    "subjects = ['s01', 's02', 's03', 's04', 's05', 's06', 's07', 's08', 's09',\n",
    "            's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17']\n",
    "\n",
    "test_subjects = ['s05', 's17']\n",
    "\n",
    "mergedActivities = ['Drinking', 'Eating', 'LyingDown', 'OpeningPillContainer', \n",
    "                      'PickingObject', 'Reading', 'SitStill', 'Sitting', 'Sleeping', \n",
    "                      'StandUp', 'UseLaptop', 'UsingPhone', 'WakeUp', 'Walking', \n",
    "                      'WaterPouring', 'Writing']\n",
    "\n",
    "specificActivities = ['Calling', 'Clapping', 'Falling', 'Sweeping', 'WashingHand', 'WatchingTV']\n",
    "\n",
    "enteringExiting = ['Entering', 'Exiting']\n",
    "\n",
    "\n",
    "def get_model_label(activity):\n",
    "    model_label = ''\n",
    "    if activity in specificActivities:\n",
    "        model_label = activity\n",
    "    elif activity in enteringExiting:\n",
    "        model_label = 'enteringExiting'\n",
    "    elif activity in mergedActivities:\n",
    "        model_label = 'other' \n",
    "    \n",
    "    return model_label\n",
    "                \n",
    "    \n",
    "for activity in activities:\n",
    "    for subject in test_subjects:\n",
    "        innerDir = subject + \"/\" + activity\n",
    "        for file in os.listdir(\"Dataset_audio/\" + innerDir):\n",
    "            if(file.endswith(\".wav\")):\n",
    "                model_label = get_model_label(activity)\n",
    "                save_prediction(\"Dataset_audio/\" + innerDir + \"/\" + file, file, model_label, subject)\n",
    "                print(subject,activity,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
